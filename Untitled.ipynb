{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbc2a298",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import scipy\n",
    "import string\n",
    "import csv\n",
    "#import nltk\n",
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('wordnet')\n",
    "#immport tokenize, stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "#import warnings\n",
    "import warnings\n",
    "#import sklearn and matplotlib\n",
    "from sklearn import preprocessing\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "#import warning\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abe74558",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2   2     5     6  How can I increase the speed of my internet co...   \n",
       "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  What is the step by step guide to invest in sh...             0  \n",
       "1  What would happen if the Indian government sto...             0  \n",
       "2  How can Internet speed be increased by hacking...             0  \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0  \n",
       "4            Which fish would survive in salt water?             0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import the data\n",
    "train=pd.read_csv('train.csv')\n",
    "train1=train.copy()\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14ddb37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72ba2590",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808575</th>\n",
       "      <td>379845</td>\n",
       "      <td>How many keywords are there in PERL Programmin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808576</th>\n",
       "      <td>155606</td>\n",
       "      <td>Is it true that there is life after death?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808577</th>\n",
       "      <td>537929</td>\n",
       "      <td>What's this coin?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808578</th>\n",
       "      <td>537931</td>\n",
       "      <td>I am having little hairfall problem but I want...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808579</th>\n",
       "      <td>537933</td>\n",
       "      <td>What is it like to have sex with your cousin?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>808580 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                           question\n",
       "0            1  What is the step by step guide to invest in sh...\n",
       "1            3  What is the story of Kohinoor (Koh-i-Noor) Dia...\n",
       "2            5  How can I increase the speed of my internet co...\n",
       "3            7  Why am I mentally very lonely? How can I solve...\n",
       "4            9  Which one dissolve in water quikly sugar, salt...\n",
       "...        ...                                                ...\n",
       "808575  379845  How many keywords are there in PERL Programmin...\n",
       "808576  155606         Is it true that there is life after death?\n",
       "808577  537929                                  What's this coin?\n",
       "808578  537931  I am having little hairfall problem but I want...\n",
       "808579  537933      What is it like to have sex with your cousin?\n",
       "\n",
       "[808580 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q1=train1.iloc[:,[2,4]]\n",
    "Q2=train1.iloc[:,[1,3]]\n",
    "df = pd.DataFrame( np.concatenate( (Q2.values, Q1.values), axis=0 ) )\n",
    "df.columns = ['id','question' ]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ef60bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.dropna(subset=\"question\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05a7b6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "# tokenizing the sentences\n",
    "tok_quora=[word_tokenize(wrd) for wrd in df.question]\n",
    "#creating training data\n",
    "Quora_training_data=[TaggedDocument(d, [i]) for i, d in enumerate(tok_quora)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebe21007",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "doc_model = Doc2Vec(Quora_training_data, vector_size = 100, window = 5, min_count = 3, epochs = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7b64301",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_embeddings(model,tokens):\n",
    "  tokens = [x for x in word_tokenize(tokens) if doc_model.wv.has_index_for(x)]\n",
    "  #if words is not present then vector becomes zero\n",
    "  if len(tokens)>=1:\n",
    "    return doc_model.infer_vector(tokens)\n",
    "  else:\n",
    "    return np.array([0]*100)\n",
    "#Storing all embedded sentence vectors in a list\n",
    "#defining empty list and iterating through all the questions\n",
    "doc_embeddings=[]\n",
    "for w in df.question:\n",
    "    doc_embeddings.append(list(fetch_embeddings(doc_model, w)))\n",
    "#conveting it into array\n",
    "doc_embeddings=np.asarray(doc_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7b4e76b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.17614569, -0.12469608,  0.12128989, ..., -0.11563963,\n",
       "         0.11872682,  0.08196142],\n",
       "       [ 0.08612118, -0.0506224 ,  0.0098575 , ..., -0.21481727,\n",
       "        -0.05770696,  0.134688  ],\n",
       "       [-0.09790493, -0.06947927, -0.01982409, ..., -0.15761417,\n",
       "         0.1562396 ,  0.08374484],\n",
       "       ...,\n",
       "       [-0.05497271,  0.01028118,  0.05481956, ...,  0.02027088,\n",
       "         0.00684827, -0.07292562],\n",
       "       [ 0.30667263, -0.17856817,  0.02931747, ..., -0.22138298,\n",
       "        -0.02321205,  0.34284461],\n",
       "       [-0.016905  ,  0.03407007,  0.00077826, ..., -0.13858332,\n",
       "        -0.05171331,  0.00330564]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9318cbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d889f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6afe61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sbert_model = SentenceTransformer('paraphrase-MiniLM-L12-v2',)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e11da5c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(808577, 384)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=[i for i in df.question]\n",
    "#lets get embeddings for each question\n",
    "sentence_embeddings_BERT= sbert_model.encode(x)\n",
    "#lets see the shape\n",
    "sentence_embeddings_BERT.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12931032",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 815973/815973 [00:01<00:00, 748487.32B/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 458495/458495 [00:00<00:00, 492900.08B/s]\n",
      "ftfy or spacy is not installed using BERT BasicTokenizer instead of SpaCy & ftfy.\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 478750579/478750579 [06:08<00:00, 1297480.60B/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 656/656 [00:00<00:00, 432416.07B/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OpenAIGPTModel(\n",
       "  (tokens_embed): Embedding(40478, 768)\n",
       "  (positions_embed): Embedding(512, 768)\n",
       "  (drop): Dropout(p=0.1, inplace=False)\n",
       "  (h): ModuleList(\n",
       "    (0): Block(\n",
       "      (attn): Attention(\n",
       "        (c_attn): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ln_1): BertLayerNorm()\n",
       "      (mlp): MLP(\n",
       "        (c_fc): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ln_2): BertLayerNorm()\n",
       "    )\n",
       "    (1): Block(\n",
       "      (attn): Attention(\n",
       "        (c_attn): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ln_1): BertLayerNorm()\n",
       "      (mlp): MLP(\n",
       "        (c_fc): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ln_2): BertLayerNorm()\n",
       "    )\n",
       "    (2): Block(\n",
       "      (attn): Attention(\n",
       "        (c_attn): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ln_1): BertLayerNorm()\n",
       "      (mlp): MLP(\n",
       "        (c_fc): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ln_2): BertLayerNorm()\n",
       "    )\n",
       "    (3): Block(\n",
       "      (attn): Attention(\n",
       "        (c_attn): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ln_1): BertLayerNorm()\n",
       "      (mlp): MLP(\n",
       "        (c_fc): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ln_2): BertLayerNorm()\n",
       "    )\n",
       "    (4): Block(\n",
       "      (attn): Attention(\n",
       "        (c_attn): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ln_1): BertLayerNorm()\n",
       "      (mlp): MLP(\n",
       "        (c_fc): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ln_2): BertLayerNorm()\n",
       "    )\n",
       "    (5): Block(\n",
       "      (attn): Attention(\n",
       "        (c_attn): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ln_1): BertLayerNorm()\n",
       "      (mlp): MLP(\n",
       "        (c_fc): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ln_2): BertLayerNorm()\n",
       "    )\n",
       "    (6): Block(\n",
       "      (attn): Attention(\n",
       "        (c_attn): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ln_1): BertLayerNorm()\n",
       "      (mlp): MLP(\n",
       "        (c_fc): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ln_2): BertLayerNorm()\n",
       "    )\n",
       "    (7): Block(\n",
       "      (attn): Attention(\n",
       "        (c_attn): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ln_1): BertLayerNorm()\n",
       "      (mlp): MLP(\n",
       "        (c_fc): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ln_2): BertLayerNorm()\n",
       "    )\n",
       "    (8): Block(\n",
       "      (attn): Attention(\n",
       "        (c_attn): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ln_1): BertLayerNorm()\n",
       "      (mlp): MLP(\n",
       "        (c_fc): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ln_2): BertLayerNorm()\n",
       "    )\n",
       "    (9): Block(\n",
       "      (attn): Attention(\n",
       "        (c_attn): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ln_1): BertLayerNorm()\n",
       "      (mlp): MLP(\n",
       "        (c_fc): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ln_2): BertLayerNorm()\n",
       "    )\n",
       "    (10): Block(\n",
       "      (attn): Attention(\n",
       "        (c_attn): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ln_1): BertLayerNorm()\n",
       "      (mlp): MLP(\n",
       "        (c_fc): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ln_2): BertLayerNorm()\n",
       "    )\n",
       "    (11): Block(\n",
       "      (attn): Attention(\n",
       "        (c_attn): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ln_1): BertLayerNorm()\n",
       "      (mlp): MLP(\n",
       "        (c_fc): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ln_2): BertLayerNorm()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from pytorch_pretrained_bert import OpenAIGPTTokenizer, OpenAIGPTModel\n",
    "#initializing the tokenizer\n",
    "tok_gpt= OpenAIGPTTokenizer.from_pretrained('openai-gpt')\n",
    "#Initializing the gpt Model\n",
    "model_gpt= OpenAIGPTModel.from_pretrained('openai-gpt')\n",
    "model_gpt.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "98b0338e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Fetch_gpt_vectors(question):\n",
    "  #tokenize words\n",
    "  words = word_tokenize(question)\n",
    "  emb = np.zeros((1,768))\n",
    "  #get vectore for each word\n",
    "  for word in words:\n",
    "      w= tok_gpt.tokenize(word)\n",
    "      indexed_words = tok_gpt.convert_tokens_to_ids(w)\n",
    "      tns_word = torch.tensor([indexed_words])\n",
    "      with torch.no_grad():\n",
    "          try:\n",
    "     #get mean vector\n",
    "            emb += np.array(torch.mean(model_gpt(tns_word),1))\n",
    "          except Exception as e:\n",
    "            continue\n",
    "  emb /= len(words)\n",
    "  return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c41fc998",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.12315906,  0.14082006, -0.065032  , ...,  0.25523008,\n",
       "        -0.29333042,  0.13614363],\n",
       "       [ 0.29858677,  0.10205473,  0.13587524, ...,  0.06204159,\n",
       "        -0.12169122,  0.01781078],\n",
       "       [ 0.12268611,  0.04076878,  0.03162665, ...,  0.16541367,\n",
       "        -0.29518024,  0.06638579],\n",
       "       ...,\n",
       "       [ 0.18672554,  0.0039593 ,  0.03602654, ...,  0.23809854,\n",
       "        -0.33544572, -0.05039982],\n",
       "       [ 0.21165202,  0.12251672,  0.10084963, ...,  0.12687523,\n",
       "        -0.27586625,  0.13541659],\n",
       "       [ 0.15088044, -0.01128635,  0.14384873, ...,  0.28454993,\n",
       "        -0.3060212 ,  0.05678449]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt_emb = np.zeros((1000, 768))\n",
    "# get vectors\n",
    "for v in range(1000):\n",
    "    txt = df.loc[v,'question']\n",
    "    gpt_emb[v] = Fetch_gpt_vectors(txt)\n",
    "gpt_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6cd63755",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "#def cosine_similarity(vec1,vec2):\n",
    "    #find the score\n",
    "    #return dot(vec1, vec2)/(norm(vec1)*norm(vec2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "857cd6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_n_questions(user,embeddings,df):\n",
    "    #getting cosine similarities of overall data set with input queries from user\n",
    "    x=cosine_similarity(user,embeddings).tolist()[0]\n",
    "    temp_list=list(x)\n",
    "    #sorting\n",
    "    sort_res = sorted(range(len(x)), key = lambda sub: x[sub])[:]\n",
    "    sim_score=[temp_list[i] for i in reversed(sort_res)]\n",
    "    #print\n",
    "    print(sort_res[0:5])\n",
    "    #index fetching\n",
    "    L=[]\n",
    "    for i in reversed(sort_res):\n",
    "        L.append(i)\n",
    "    #get the index from dataframe\n",
    "    return df.iloc[L[0:5], [0,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e47529e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_vector(query,model):\n",
    "    print(query)\n",
    "    #Doc2vec model\n",
    "    if model=='Doc2Vec':\n",
    "      k=fetch_embeddings(doc_model,query)\n",
    "      k=k.reshape(1, -1)\n",
    "    # sbert  model\n",
    "    elif model=='BERT':\n",
    "      k=sbert_model.encode(str(query))\n",
    "      k=k.reshape(1, -1)\n",
    "    # gpt model\n",
    "    elif model=='GPT':\n",
    "      k=Fetch_gpt_vectors(query)\n",
    "    return k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fdc05acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How is Narendra Modi as a person?\n",
      "[719952, 478487, 488544, 365768, 364721]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2166</th>\n",
       "      <td>4310</td>\n",
       "      <td>How is Narendra Modi as a person?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527387</th>\n",
       "      <td>4310</td>\n",
       "      <td>How is Narendra Modi as a person?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491967</th>\n",
       "      <td>4310</td>\n",
       "      <td>How is Narendra Modi as a person?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108565</th>\n",
       "      <td>178349</td>\n",
       "      <td>How is Sachin Tendulkar as in person?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596409</th>\n",
       "      <td>291671</td>\n",
       "      <td>How is Jimmy Wales as a person?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                               question\n",
       "2166      4310      How is Narendra Modi as a person?\n",
       "527387    4310      How is Narendra Modi as a person?\n",
       "491967    4310      How is Narendra Modi as a person?\n",
       "108565  178349  How is Sachin Tendulkar as in person?\n",
       "596409  291671        How is Jimmy Wales as a person?"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_n_questions(get_input_vector('How is Narendra Modi as a person?','Doc2Vec'),doc_embeddings,df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9375b5e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How is Narendra Modi as a person?\n",
      "[674, 341, 119, 923, 67]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>812</th>\n",
       "      <td>1619</td>\n",
       "      <td>What is a GDP?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>1012</td>\n",
       "      <td>What is Zika virus and how is it transmitted?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>790</th>\n",
       "      <td>1575</td>\n",
       "      <td>Can fossil records be used as evidence for evo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657</th>\n",
       "      <td>1311</td>\n",
       "      <td>What are genders?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>1082</td>\n",
       "      <td>What is bss engineer?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                           question\n",
       "812  1619                                     What is a GDP?\n",
       "507  1012      What is Zika virus and how is it transmitted?\n",
       "790  1575  Can fossil records be used as evidence for evo...\n",
       "657  1311                                  What are genders?\n",
       "542  1082                              What is bss engineer?"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_n_questions(get_input_vector('How is Narendra Modi as a person?','GPT'),gpt_emb,df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "52f5a29a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How is Narendra Modi as a person?\n",
      "[114737, 470009, 113689, 34383, 603254]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>527387</th>\n",
       "      <td>4310</td>\n",
       "      <td>How is Narendra Modi as a person?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491967</th>\n",
       "      <td>4310</td>\n",
       "      <td>How is Narendra Modi as a person?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2166</th>\n",
       "      <td>4310</td>\n",
       "      <td>How is Narendra Modi as a person?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616382</th>\n",
       "      <td>147622</td>\n",
       "      <td>What's Narendra Modi like in person?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87677</th>\n",
       "      <td>147622</td>\n",
       "      <td>What's Narendra Modi like in person?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                              question\n",
       "527387    4310     How is Narendra Modi as a person?\n",
       "491967    4310     How is Narendra Modi as a person?\n",
       "2166      4310     How is Narendra Modi as a person?\n",
       "616382  147622  What's Narendra Modi like in person?\n",
       "87677   147622  What's Narendra Modi like in person?"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_n_questions(get_input_vector('How is Narendra Modi as a person?','BERT'),sentence_embeddings_BERT,df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ec29ed0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import os\n",
    "import string\n",
    "import csv\n",
    "#import nltk\n",
    "import nltk\n",
    "\n",
    "#import tokenizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "#import warnings\n",
    "import warnings\n",
    "#import sklearn and matplotlib\n",
    "from sklearn import preprocessing\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "#import warning\n",
    "warnings.filterwarnings('ignore')\n",
    "import re\n",
    "from string import punctuation\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "#import Tokenizer from keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "#importing Keras necessary libraries\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Embedding, Dense, Dropout, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "da5fb25b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2   2     5     6  How can I increase the speed of my internet co...   \n",
       "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  What is the step by step guide to invest in sh...             0  \n",
       "1  What would happen if the Indian government sto...             0  \n",
       "2  How can Internet speed be increased by hacking...             0  \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0  \n",
       "4            Which fish would survive in salt water?             0  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quora_questions=pd.read_csv('train.csv')\n",
    "quora_questions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0b70f90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "quora_questions=quora_questions.dropna(subset=[\"question1\",\"question2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a24502ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for data cleaning\n",
    "def txt_process(input_text):\n",
    "    # Removing punctuation from input text\n",
    "    input_text = ''.join([x for x in input_text if x not in punctuation])\n",
    "    # Cleaning the text\n",
    "    input_text = re.sub(r\"[^A-Za-z0-9]\", \" \", input_text)\n",
    "    input_text = re.sub(r\"\\'s\", \" \", input_text)\n",
    "    # remove stop words\n",
    "    input_text = input_text.split()\n",
    "    input_text = [x for x in input_text if not x in stop_words]\n",
    "    input_text = \" \".join(input_text)\n",
    "    # Return a list of words\n",
    "    return(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3b07d300",
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying above function on both question ids\n",
    "quora_questions['question1_cleaned'] = quora_questions.apply(lambda x: txt_process(x['question1']), axis = 1)\n",
    "quora_questions['question2_cleaned'] = quora_questions.apply(lambda x: txt_process(x['question2']), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "05e7b938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>question1_cleaned</th>\n",
       "      <th>question2_cleaned</th>\n",
       "      <th>tokenizer_1</th>\n",
       "      <th>tokenizer_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "      <td>What step step guide invest share market india</td>\n",
       "      <td>What step step guide invest share market</td>\n",
       "      <td>[1, 1221, 1221, 2471, 481, 669, 296, 9]</td>\n",
       "      <td>[1, 1221, 1221, 2471, 481, 669, 296]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "      <td>What story Kohinoor KohiNoor Diamond</td>\n",
       "      <td>What would happen Indian government stole Kohi...</td>\n",
       "      <td>[1, 465, 11810, 11810, 4500]</td>\n",
       "      <td>[1, 14, 117, 36, 163, 11186, 11810, 11810, 450...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "      <td>How I increase speed internet connection using...</td>\n",
       "      <td>How Internet speed increased hacking DNS</td>\n",
       "      <td>[3, 2, 145, 350, 274, 1750, 89, 2713]</td>\n",
       "      <td>[3, 274, 350, 3206, 1239, 11172]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "      <td>Why I mentally lonely How I solve</td>\n",
       "      <td>Find remainder math2324math divided 2423</td>\n",
       "      <td>[4, 2, 2701, 2623, 3, 2, 544]</td>\n",
       "      <td>[40, 4041, 84518, 2356, 84519]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "      <td>Which one dissolve water quikly sugar salt met...</td>\n",
       "      <td>Which fish would survive salt water</td>\n",
       "      <td>[8, 15, 7038, 160, 36270, 1834, 1948, 10451, 1...</td>\n",
       "      <td>[8, 1848, 14, 1141, 1948, 160]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2   2     5     6  How can I increase the speed of my internet co...   \n",
       "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           question2  is_duplicate  \\\n",
       "0  What is the step by step guide to invest in sh...             0   \n",
       "1  What would happen if the Indian government sto...             0   \n",
       "2  How can Internet speed be increased by hacking...             0   \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0   \n",
       "4            Which fish would survive in salt water?             0   \n",
       "\n",
       "                                   question1_cleaned  \\\n",
       "0     What step step guide invest share market india   \n",
       "1               What story Kohinoor KohiNoor Diamond   \n",
       "2  How I increase speed internet connection using...   \n",
       "3                  Why I mentally lonely How I solve   \n",
       "4  Which one dissolve water quikly sugar salt met...   \n",
       "\n",
       "                                   question2_cleaned  \\\n",
       "0           What step step guide invest share market   \n",
       "1  What would happen Indian government stole Kohi...   \n",
       "2           How Internet speed increased hacking DNS   \n",
       "3           Find remainder math2324math divided 2423   \n",
       "4                Which fish would survive salt water   \n",
       "\n",
       "                                         tokenizer_1  \\\n",
       "0            [1, 1221, 1221, 2471, 481, 669, 296, 9]   \n",
       "1                       [1, 465, 11810, 11810, 4500]   \n",
       "2              [3, 2, 145, 350, 274, 1750, 89, 2713]   \n",
       "3                      [4, 2, 2701, 2623, 3, 2, 544]   \n",
       "4  [8, 15, 7038, 160, 36270, 1834, 1948, 10451, 1...   \n",
       "\n",
       "                                         tokenizer_2  \n",
       "0               [1, 1221, 1221, 2471, 481, 669, 296]  \n",
       "1  [1, 14, 117, 36, 163, 11186, 11810, 11810, 450...  \n",
       "2                   [3, 274, 350, 3206, 1239, 11172]  \n",
       "3                     [40, 4041, 84518, 2356, 84519]  \n",
       "4                     [8, 1848, 14, 1141, 1948, 160]  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stacking\n",
    "question_text = np.hstack([quora_questions.question1_cleaned, quora_questions.question2_cleaned])\n",
    "#tokenizing\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(question_text)\n",
    "#creating new columns for both ids where tokenized form of sentence is created\n",
    "quora_questions['tokenizer_1'] = tokenizer.texts_to_sequences(quora_questions.question1_cleaned)\n",
    "quora_questions['tokenizer_2'] = tokenizer.texts_to_sequences(quora_questions.question2_cleaned)\n",
    "quora_questions.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bb6901c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "quora_questions['tokenizer'] = quora_questions['tokenizer_1'] + quora_questions['tokenizer_2']\n",
    "#defining max length\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "m_len = 500\n",
    "#max tokens\n",
    "max_token = np.max(quora_questions.tokenizer.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ce08a3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining X and target data\n",
    "y = quora_questions[['is_duplicate']]\n",
    "X = quora_questions[['tokenizer']]\n",
    "#padding X with a maximum length\n",
    "X = sequence.pad_sequences(X.tokenizer, maxlen = m_len)\n",
    "#splitting data into train and test\n",
    "X_train,X_test,y_train,y_test=train_test_split(X, y, test_size=0.25, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9923f0d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 64)          4480000   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, None, 64)          0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 16)                5184      \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,485,201\n",
      "Trainable params: 4,485,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#defining the LSTM model\n",
    "quora_model = Sequential()\n",
    "#adding embeedding layer\n",
    "quora_model.add(Embedding(70000, 64))\n",
    "#adding drop out layer\n",
    "quora_model.add(Dropout(0.15))\n",
    "#LSTM layer\n",
    "quora_model.add(LSTM(16))\n",
    "#adding sigmoid layer\n",
    "\n",
    "\n",
    "quora_model.add(Dense(1, activation = 'sigmoid'))\n",
    "#defining loss and optimizer\n",
    "quora_model.compile(loss='binary_crossentropy', optimizer='SGD', metrics=['accuracy'])\n",
    "quora_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8e8cbba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4738/4738 [==============================] - 150s 32ms/step - loss: 0.5995 - accuracy: 0.6766 - val_loss: 0.5821 - val_accuracy: 0.6932\n",
      "Epoch 2/20\n",
      "4738/4738 [==============================] - 153s 32ms/step - loss: 0.5647 - accuracy: 0.7115 - val_loss: 0.5533 - val_accuracy: 0.7225\n",
      "Epoch 3/20\n",
      "4738/4738 [==============================] - 148s 31ms/step - loss: 0.5470 - accuracy: 0.7262 - val_loss: 0.5476 - val_accuracy: 0.7255\n",
      "Epoch 4/20\n",
      "4738/4738 [==============================] - 143s 30ms/step - loss: 0.5359 - accuracy: 0.7344 - val_loss: 0.5500 - val_accuracy: 0.7263\n",
      "Epoch 5/20\n",
      "4738/4738 [==============================] - 141s 30ms/step - loss: 0.5276 - accuracy: 0.7404 - val_loss: 0.5300 - val_accuracy: 0.7404\n",
      "Epoch 6/20\n",
      "4738/4738 [==============================] - 144s 30ms/step - loss: 0.5210 - accuracy: 0.7452 - val_loss: 0.5242 - val_accuracy: 0.7436\n",
      "Epoch 7/20\n",
      "4738/4738 [==============================] - 145s 31ms/step - loss: 0.5163 - accuracy: 0.7486 - val_loss: 0.5207 - val_accuracy: 0.7471\n",
      "Epoch 8/20\n",
      "4738/4738 [==============================] - 144s 30ms/step - loss: 0.5115 - accuracy: 0.7520 - val_loss: 0.5189 - val_accuracy: 0.7475\n",
      "Epoch 9/20\n",
      "4738/4738 [==============================] - 144s 30ms/step - loss: 0.5080 - accuracy: 0.7544 - val_loss: 0.5176 - val_accuracy: 0.7486\n",
      "Epoch 10/20\n",
      "4738/4738 [==============================] - 145s 31ms/step - loss: 0.5046 - accuracy: 0.7566 - val_loss: 0.5159 - val_accuracy: 0.7484\n",
      "Epoch 11/20\n",
      "4738/4738 [==============================] - 146s 31ms/step - loss: 0.5017 - accuracy: 0.7581 - val_loss: 0.5125 - val_accuracy: 0.7517\n",
      "Epoch 12/20\n",
      "4738/4738 [==============================] - 144s 30ms/step - loss: 0.4987 - accuracy: 0.7601 - val_loss: 0.5186 - val_accuracy: 0.7446\n",
      "Epoch 13/20\n",
      "4738/4738 [==============================] - 146s 31ms/step - loss: 0.4960 - accuracy: 0.7623 - val_loss: 0.5085 - val_accuracy: 0.7546\n",
      "Epoch 14/20\n",
      "4738/4738 [==============================] - 144s 30ms/step - loss: 0.4939 - accuracy: 0.7640 - val_loss: 0.5075 - val_accuracy: 0.7541\n",
      "Epoch 15/20\n",
      "4738/4738 [==============================] - 145s 31ms/step - loss: 0.4915 - accuracy: 0.7659 - val_loss: 0.5087 - val_accuracy: 0.7540\n",
      "Epoch 16/20\n",
      "4738/4738 [==============================] - 4419s 933ms/step - loss: 0.4890 - accuracy: 0.7666 - val_loss: 0.5077 - val_accuracy: 0.7532\n",
      "Epoch 17/20\n",
      "4738/4738 [==============================] - 151s 32ms/step - loss: 0.4870 - accuracy: 0.7684 - val_loss: 0.5127 - val_accuracy: 0.7528\n",
      "Epoch 18/20\n",
      "4738/4738 [==============================] - 150s 32ms/step - loss: 0.4853 - accuracy: 0.7689 - val_loss: 0.5084 - val_accuracy: 0.7524\n",
      "Epoch 19/20\n",
      "4738/4738 [==============================] - 151s 32ms/step - loss: 0.4829 - accuracy: 0.7706 - val_loss: 0.5038 - val_accuracy: 0.7587\n",
      "Epoch 20/20\n",
      "4738/4738 [==============================] - 146s 31ms/step - loss: 0.4813 - accuracy: 0.7714 - val_loss: 0.5041 - val_accuracy: 0.7584\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20cada1a520>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quora_model.fit(X_train, y_train, epochs = 20, batch_size=64,validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0db7e726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7779232557756047\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Not similar       0.79      0.89      0.83    191262\n",
      "     similar       0.76      0.59      0.66    111953\n",
      "\n",
      "    accuracy                           0.78    303215\n",
      "   macro avg       0.77      0.74      0.75    303215\n",
      "weighted avg       0.78      0.78      0.77    303215\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn.metrics import classification_report\n",
    "#prediction on train data\n",
    "tr_prediction=quora_model.predict(X_train)\n",
    "#replacing probabilities >0.5 with 1 and other 0\n",
    "tr_prediction[tr_prediction>0.5]=1\n",
    "tr_prediction[tr_prediction<0.5]=0\n",
    "tr_prediction\n",
    "#true values of train data\n",
    "tr_true=y_train.values\n",
    "#accuracy\n",
    "Accuracy=sklearn.metrics.accuracy_score(np.array(tr_true),\n",
    "                                     np.array(tr_prediction))\n",
    "print(Accuracy)\n",
    "\n",
    "#classification report with f1 score\n",
    "print(classification_report(tr_true, tr_prediction, target_names=['Not similar','similar']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "12f96e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 75.838016 %\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Not similar       0.77      0.87      0.82     63762\n",
      "     similar       0.72      0.56      0.63     37310\n",
      "\n",
      "    accuracy                           0.76    101072\n",
      "   macro avg       0.75      0.72      0.73    101072\n",
      "weighted avg       0.75      0.76      0.75    101072\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_prediction=quora_model.predict(X_test)\n",
    "#generating classes\n",
    "test_prediction[test_prediction>0.5]=1\n",
    "test_prediction[test_prediction<0.5]=0\n",
    "test_prediction\n",
    "#true values for test\n",
    "test_true=y_test.values\n",
    "# accuracy on test data\n",
    "Accuracy=sklearn.metrics.accuracy_score(np.array(test_true),\n",
    "                                     np.array(test_prediction))\n",
    "print('Accuracy is %f'%(Accuracy*100)+' %')\n",
    "\n",
    "print(classification_report(test_true, test_prediction, target_names=['Not similar','similar']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "34a90561",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similarity_score(q1,q2):\n",
    "  #clean first question\n",
    "  Q1_C=  txt_process(q1)\n",
    "  #print(q1)\n",
    "  #clean first question\n",
    "  Q2_C = txt_process(q2)\n",
    "  #print(q2)\n",
    "  #converting 1st question into tokens\n",
    "  Q1_C = tokenizer.texts_to_sequences([Q1_C])\n",
    "  #converting 2nd question into token\n",
    "  Q2_C = tokenizer.texts_to_sequences([Q2_C])\n",
    "  #combining both tokens as we did for train data\n",
    "  Q_final = Q1_C[0] + Q2_C[0]\n",
    "  #padding combined sequence to max length\n",
    "  Q_Test = sequence.pad_sequences([Q_final], maxlen = 500)\n",
    "  #predicting probability of given pair\n",
    "  Prob=quora_model.predict(Q_Test)\n",
    "  print(Prob)\n",
    "  #if p>0.5 then similar\n",
    "  if Prob[0]>0.5:\n",
    "    return 'Quora Questions are similar'\n",
    "  else:\n",
    "    return 'Quora Questions are Not similar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "af302f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5147049]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Quora Questions are similar'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_similarity_score('is there life after death?','Do people belive in after life')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "780ef542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.49732614]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Quora Questions are Not similar'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_similarity_score('Who is Narendra Modi?','What is identity of Narendra Modi?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8c62691b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.20287153]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Quora Questions are Not similar'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_similarity_score('Should I have a hair transplant at age 24? How much would it cost?','How much cost does hair transplant require?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fab02f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
